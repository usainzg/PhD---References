\documentclass[a4paper, 11pt]{article}
%\documentclass[]{book}
\usepackage{unai}

\input config/unai_config

% declare all acronyms
%\newacronym{usg}{USG}{Unai Sainz de la Maza Gamboa}
%\makeglossaries

\title{PhD - References}
\author{Unai Sainz de la Maza Gamboa}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\clearpage

% \input{content/papers}
% \cleardoublepage
% \input{content/resources}
% \cleardoublepage
% \input{content/polly}

\section{Compiler-based distributed computing techniques (thesis title?)}
\subsection{Summary}
Compute-intensive applications running on clusters of shared-memory computers typically utilize OpenMP and MPI for implementation. These applications are challenging to program, debug, and maintain. Additionally, achieving performance portability is often limited, requiring several program transformations at multiple levels of the software and hardware stack to leverage features like parallelism and granularity. Finally, specific characteristics of the target system, such as network topology and node capacity, must be considered to achieve high-performing code.

Performance portability and user productivity are major concerns for modern compilers, as significant code reorganization and restructuring are often required to adapt applications to the resources of a computer cluster. Consequently, polyhedral auto-transformation frameworks have garnered significant interest in general-purpose compilation due to their capability to identify and implement complex loop transformations that extract high performance from modern architectures. These frameworks automatically identify loop transformations that enhance locality, parallelism, minimize latency, or achieve a combination of these improvements.

\begin{itemize}
    \item In this thesis... we try to combine polyhedral compilation techniques and domain-specific knowledge to solve distributed computing problems such as scheduling or communication optimization... ok?
\end{itemize}

\subsection{Background}
The polyhedral model is a mathematical representation of programs that simplifies both analysis and restructuring. It provides a compact and expressive way to describe parallelization and optimization problems. Unlike operational or syntactic representations, this model is closer to program execution because it operates on individual statement iterations or instances. For each instance, the optimizing algorithm computes a mapping to determine the execution time (time mapping or scheduling) and/or the processor on which it will run (space mapping or placement) \cite{}.

\begin{itemize}
    \item Pioneer work, how polyhedral is integrated into compilers, general workflow (dep analysis, schedule transformation, code generation).
    \item Previous work on automatic parallelization in distributed computing using polyhedral. Difficult to add relevant information such as topology or nodes capacity.
    \item More?
\end{itemize}

\subsection{Objectives}
Based on the issues outlined in the previous section, the research question to be addressed in this Ph.D. thesis is: ...

\subsection{Methodology}
The research methodology employed in this thesis is based on an experimental approach and a software engineering method encompassing four stages: observing existing solutions, proposing improved solutions, developing the proposed solutions, and measuring and analyzing the outcomes \cite{adrion1993research}. This iterative methodology is repeated to refine the solutions. It parallels the stages of the classical scientific method: proposing a question, formulating a hypothesis, making predictions, and validating the hypothesis.

\begin{enumerate}
    \item Observe existing solutions: this is an exploratory phase where the literature and state-of-the-art tools related to our research field are studied to identify potential improvements.
    \item Propose better solutions: this phase focuses on designing and analyzing improved solutions, aiming to surpass the limitations of previous proposals or enhance existing methods from the literature.
    \item Build or develop the solutions: in this phase, we concentrate on constructing a prototype to demonstrate the feasibility of the solution.
    \item Measure and analyze the new solutions: finally, the implemented prototypes are empirically evaluated and compared with various alternatives. The goal of this evaluation is to validate the proposed solution and confirm that the problems identified in the initial step have been resolved.
\end{enumerate}

\subsection{Work plan}
\subsubsection{Part I: Topology-aware distributed data communication optimization?}
\subsubsection{Part II: ...}


\subsection{Scientific or social interest}

most outstanding bibliography expressly comprising the following: a) Whether or not it is expected that the objectives of the Doctoral Thesis project and its defense are achieved by the applicant in the 3 years of full-time help and b) That the project will abide by the applicable ethical principles (maximum 5 pages, Arial 9 single line spacing) 

\section{Polyhedral papers}\label{sec:polly_papers}
\subsection{Topics (taken from IMPACT CFP)}
\begin{itemize}
    \item Program optimization (automatic parallelization, tiling, etc.)
    \item Code generation.
    \item Data/communication management on GPUs, accelerators and distributed systems.
    \item Hardware/high-level synthesis for affine programs.
    \item Static analysis.
    \item Program verification.
    \item Model checking.
    \item Theoretical foundations of the polyhedral model.
    \item Extensions of the polyhedral model.
    \item Scalability and robustness of polyhedral compilation techniques.
\end{itemize}

\subsection{Courses}
\begin{itemize}
    \item Polyhedral seminar (C. Alias): \href{https://gitlab.inria.fr/alias/polyhedral-seminar}{Link}
    \item UCLA CS33/CS31 (LN. Pouchet): \href{https://web.cs.ucla.edu/~pouchet/index.html#lectures}{Link}
    \item Presburger Formulas and Polyhedral Compilation Tutorial (S. Verdoolaege): \href{https://lirias.kuleuven.be/bitstream/123456789/523109/3/polycomp-tutorial-v0.02.pdf}{Link}
    \item Static Analysis and Optimizing Compilers (C. Alias): \href{https://gitlab.inria.fr/alias/cours-m2-cr14}{Link}
    \item Polyhedral Compilation as a Design Pattern for Compilers (A.Cohen): \href{https://www.youtube.com/watch?v=mt6pIpt5Wk0}{Link 1} and \href{https://www.youtube.com/watch?v=3TNT5rFVTUY}{Link 2}
\end{itemize}

\subsection{The Polyhedral Model Is More Widely Applicable Than You Think}
\cite{Benabderrahmane2010ThePM}

\subsection{Modelling linear algebra kernels as polyhedral volume operations}
In \cite{friebel2022modelling}, programs are represented as sequences of operations on indexed volumes characterized by their element-wise dependencies, efficiently implementing compound kernels by partitioning and specializing over index domains.
\begin{itemize}
    \item They generalize over arrays and define a volume as an aggregate value comprising indexed element values (scalars). Volume is characterized by an index domain, which is a polyhedron of all element indices.
    \item Volumes permit arbitrary polyhedral index domains and are intended to model the structural properties of data, as well as memory when needed.
    \item They perform dynamic shape inference of input/output/intermediate volumes. They use affine pattern matching to identify regions of interest (sparse regions in a volume) and specialize over them. They separate computation from memory (operational semantics based on general affine volumes, not strictly hyperrectangular ones).
    \item The proposed model can be used on the MLIR linalg abstraction to generalize tiling and other partitioning transformations to arbitrary tensor programs.
\end{itemize}
The main idea is to detect sparsity and other structural properties, and act on them by partitioning computations. State-of-the-art compilers struggle to separate the different regions of the program, which may lead to sub-optimal performance. However, their model can conveniently identify all kernel regions, i.e., dense, sparse, constant, and corners. This empowers specializing over these regions, e.g., by using sparse compiler optimizations for sparse regions or offloading them to a sparsity-aware hardware target and mapping dense regions to external library calls.

\subsection{ParameTrick: Coefficient Generalization for Faster Polyhedral Scheduling}
In \cite{consolaro24-parametrick}, 

\subsection{A practical tile size selection model for affine loop nests}

\subsection{Maximal Atomic irRedundant Sets: a Usage-based Dataflow Partitioning Algorithm}

\subsection{A polyhedral compilation framework for loops with dynamic data-dependent bounds}

\subsection{Generating SIMD Instructions for Cerebras CS-1 using Polyhedral Compilation Techniques}
In \cite{verdoolaege2020generating}, they use polyhedral compilation to generate SIMD instructions for the cerebras cs-1 computing system. More precisely, they use polyhedral operations such as variable compression and fixed-sized box hull.
\begin{itemize}
    \item SIMD engine that can mimic a rectangular loop nest of depth at most four. For this, is important to represent the set of computation instances as a rectangular domain.
    \item They rely on \textit{isl} library for manipulating sets of integer tuples described by Presburger formulas (a first order logic formula involving affine expressions, equality and the less-than-or-equal relation). 
    \item Variable compression exploits the equality constraints in the description of a set to obtain a set with the same number of points, but of a lower dimensionality.
    \item Fixed-size box hull operation examines the constraints of a binary relation to find an overapproximation where the range can be described as a rectangular box with fixed size and an offset that depends on the domain variables and the symbolic constants.
    \item Target architecture: MPPA (Massively Parallel Processor Array), consisting of a 2-dimensional grid of PEs (processing elements) that communicate with their nearest neighbors in the four cardinal directions. Memory distributed overt the PEs and hardware performs dataflow scheduling. (not much public details).
\end{itemize}
The main idea is to expose rectangle sets of operations that can be mapped to the advanced SIMD operations of the Cerebras CS-1 architecture.

\subsection{Polygeist: Affine C in MLIR}

\subsection{Automatic multi-dimensional pipelining for high-level synthesis of dataflow accelerators}

\subsection{Tile size selection of affine programs for GPGPUs using polyhedral cross-compilation}
In \cite{Abdelaal2021TileSS}, they use Integer Linear Programming (ILP) constraints and objectives in a cross-compiler fashion to faithfully and effectively mimic the transformations applied in a polyhedral GPU compiler (PPCG) to compute resource-conscious tile sizes for affine programs.

\subsection{PolySA: Polyhedral-Based Systolic Array Auto-Compilation}
In \cite{Cong2018PolySAPS}, they present PolySA, the first fully automated compilation framework for generating high performance systolic array architectures on the FPGA that leverages recent advances in high-level synthesis and can generate optimal designs in one hour with performance comparable to state-of-the-art manual designs.

\subsection{AutoSA: A Polyhedral Compiler for High-Performance Systolic Arrays on FPGA}
In \cite{Wang2021AutoSAAP}, they present AutoSA, an end-to-end compilation framework for generating systolic arrays on FPGA, based on the polyhedral framework, and further incorporates a set of optimizations on different dimensions to boost performance.

\subsection{Scalable Polyhedral Compilation, Syntax vs. Semantics: 1–0 in the First Round}
In \cite{48842}, a family of techniques is introduced called offline statement clustering, which integrates transparently into the flow of a state-of-the-art polyhedral compiler and can reduce the scheduling time by a factor of 6 without inducing a significant loss in optimization opportunities.

\subsection{Polyhedral Compilation for Racetrack Memories}
In \cite{khan2020polyhedral}, they present the first automatic compilation framework that optimizes static loop programs over arrays for linear-latency memories, extending the polyhedral compilation framework Polly to generate code that maximizes accesses to the same or consecutive locations, thereby minimizing the number of shifts.

\subsection{Polyhedral Compilation for Multi-dimensional Stream Processing}
In \cite{leben2019polyhedral}, they present a method that involves a novel polyhedral schedule transformation called periodic tiling that enables efficient execution of programming languages with unbounded recurrence equations, as well as optimization of existing languages from which this form can be derived.

\subsection{An Autotuning Framework for Scalable Execution of Tiled Code via Iterative Polyhedral Compilation}

\subsection{Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts}
In \cite{mayer24-fpgas}, polyhedral methods are used to generate stencil-specific cache-structures of the right sizes on the FPGA and to fill and flush them efficiently with wide bursts during stencil execution. They derive the appropriate directives and code restructurings from stencil codes so that the FPGA compiler generates fast stencil hardware.
\begin{itemize}
    \item From previous attempts: HLS cannot turn the tiled loop into hardware pipelines (as the loop boundaries and increments are too complex for the HLS to detect patterns). On CPUs or GPUs tiled loops run faster since their data locality exploits the built-in cache hierarchy, however, on FPGAs there are no caches, there is no benefit from tiling alone. In general, the HLS generates from the tiled loop a hardware block (kernel) with connections to an FPGA bus through which the kernel directly talks to the DDR.
    \item Polyhedral methods are used to understand the access patterns we can statically determine (a) the stencil-specific best cache sizes and (b) pre-load exactly what is needed and spill what is no longer needed. But the polyhedral method can also (c) help improve the burst behavior. They also (d) inline the cache functionality, i.e., use buffer arrays and load operations within the stencil.
\end{itemize}
This work uses loop tiling to improve locality, adds buffers and directives to generate inlined cache-like hardware circuits that exploit that locality, and calculates a data-shipment that uses wide bursts to fill these caches, i.e., a polyhedral-based code generator for FPGAs.

\subsection{Modelling linear algebra kernels as polyhedral volume operations}

\subsection{Automated Partitioning of Data-Parallel Kernels using Polyhedral Compilation}

\subsection{Superloop Scheduling: Loop Optimization via Direct Statement Instance Reordering}
In \cite{bastoul2023superloop}, they propose a different approach to affine scheduling construction called superloop scheduling. A 7-step loop optimization process:
\begin{itemize}
    \item Iteration space bounding: limit the number of iterations and replaces the parameters with known values.
    \item Full loop unrolling: transform the code to a sequence of statement instances.
    \item Statement instance reordering: transform the unrolled code via direct reasoning and manipulation of the statement instances. Parallel block extraction and internal reordering to enable vectorization. Also, basic block level techniques such as superword level parallelisation \cite{Mendis_2018} to enable possibly unprecedented loop vectorization opportunities. Reordering policies should include constraints or mechanisms to favor some regularity when possible.
    \item Nested loop recognition (NLR): recover loops in a fast and incremental way \cite{ketterlin2008prediction} from a trace comprised of tagged vectors of numbers. NLR is able to recover arbitrarily deep and/or complex affine loop nests from their traces.
    \item Affine scheduling reconstruction: build an affine scheduling expression from the loop structure and the mapping information present in NLR’s output. Also, attempt to recover parameters, e.g. through pattern-matching.
    \item Legality check: verify the scheduling correctness on the original input code using the Candl tool, and may assess its properties such as parallel and vector dimensions.
    \item Code generation: produce the optimized code that implements the scheduling using, e.g., CLooG \cite{bastoul2004code}. The optimization is different than both Feautrier \cite{feautrier1992some} (which favors k, i, j version with internal parallelism) and Pluto without tiling \cite{bondhugula2008practical} (which splits S0 and S1 in two loop nests to enable i, k, j order for S1, or uses less CPU-efficient i, j, k).
\end{itemize}
Two families of techniques for affine scheduling construction:
\begin{itemize}
    \item Compute the scheduling by solving systems of affine constraints: proposed by Feautrier \cite{feautrier1992some} and has set the ground for many later techniques, the Pluto algorithm designed by Bondhugula et al. to extract outermost parallelism, data locality and tilable loops \cite{bondhugula2008practical}, and a number of variants that differ in the way the affine constraint system is built.
    \item Build the affine scheduling by composition of basic primitives: proposed by Kelly and Pugh \cite{kelly1998framework} and improved by many authors, e.g., Baghdadi et al. who propose a rich scheduling language for the Tiramisu framework \cite{baghdadi2019tiramisu}. 
\end{itemize}
However, in this work, they present the seed for a new family that builds affine scheduling from finest-grain statement instance reordering and loop reconstruction. Which could have a significant potential for exploiting custom vector instructions.

\textbf{Important note:} presented at IMPACT 2023, a short (working) paper.

\subsection{Pipelined Multithreading Generation in a Polyhedral Compiler}

\subsection{Compiling affine loop nests for distributed-memory parallel architectures}
\cite{bondhugulaCompilingAffineLoop2013}

\subsection{Dynamic memory access monitoring based on tagged memory}
\cite{dathathriDynamicMemoryAccess2013}

\subsection{Effective automatic computation placement and data allocation for parallelization of regular programs}
\cite{reddyEffectiveAutomaticComputation2014}

\cleardoublepage
\bibliographystyle{apalike}
\bibliography{refs, references}

%\printglossary[type=\acronymtype]
\end{document}