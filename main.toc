\contentsline {section}{\numberline {1}Compiler-based distributed computing techniques (\textcolor {BrickRed}{thesis title?})}{3}{section.1}%
\contentsline {subsection}{\numberline {1.1}Summary}{3}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Background}{3}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Objectives}{4}{subsection.1.3}%
\contentsline {subsection}{\numberline {1.4}Methodology}{4}{subsection.1.4}%
\contentsline {subsection}{\numberline {1.5}Work plan}{5}{subsection.1.5}%
\contentsline {subsubsection}{\numberline {1.5.1}Part I: Topology-aware distributed data communication optimization?}{5}{subsubsection.1.5.1}%
\contentsline {subsubsection}{\numberline {1.5.2}Part II: ...}{5}{subsubsection.1.5.2}%
\contentsline {subsection}{\numberline {1.6}Scientific or social interest}{5}{subsection.1.6}%
\contentsline {section}{\numberline {2}Polyhedral papers}{6}{section.2}%
\contentsline {subsection}{\numberline {2.1}Topics (taken from IMPACT CFP)}{6}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Courses}{6}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}The Polyhedral Model Is More Widely Applicable Than You Think}{6}{subsection.2.3}%
\contentsline {subsection}{\numberline {2.4}Modelling linear algebra kernels as polyhedral volume operations}{7}{subsection.2.4}%
\contentsline {subsection}{\numberline {2.5}ParameTrick: Coefficient Generalization for Faster Polyhedral Scheduling}{7}{subsection.2.5}%
\contentsline {subsection}{\numberline {2.6}A practical tile size selection model for affine loop nests}{8}{subsection.2.6}%
\contentsline {subsection}{\numberline {2.7}Maximal Atomic irRedundant Sets: a Usage-based Dataflow Partitioning Algorithm}{8}{subsection.2.7}%
\contentsline {subsection}{\numberline {2.8}A polyhedral compilation framework for loops with dynamic data-dependent bounds}{8}{subsection.2.8}%
\contentsline {subsection}{\numberline {2.9}Generating SIMD Instructions for Cerebras CS-1 using Polyhedral Compilation Techniques}{8}{subsection.2.9}%
\contentsline {subsection}{\numberline {2.10}Polygeist: Affine C in MLIR}{9}{subsection.2.10}%
\contentsline {subsection}{\numberline {2.11}Automatic multi-dimensional pipelining for high-level synthesis of dataflow accelerators}{9}{subsection.2.11}%
\contentsline {subsection}{\numberline {2.12}Tile size selection of affine programs for GPGPUs using polyhedral cross-compilation}{9}{subsection.2.12}%
\contentsline {subsection}{\numberline {2.13}PolySA: Polyhedral-Based Systolic Array Auto-Compilation}{9}{subsection.2.13}%
\contentsline {subsection}{\numberline {2.14}AutoSA: A Polyhedral Compiler for High-Performance Systolic Arrays on FPGA}{9}{subsection.2.14}%
\contentsline {subsection}{\numberline {2.15}Scalable Polyhedral Compilation, Syntax vs. Semantics: 1â€“0 in the First Round}{9}{subsection.2.15}%
\contentsline {subsection}{\numberline {2.16}Polyhedral Compilation for Racetrack Memories}{9}{subsection.2.16}%
\contentsline {subsection}{\numberline {2.17}Polyhedral Compilation for Multi-dimensional Stream Processing}{10}{subsection.2.17}%
\contentsline {subsection}{\numberline {2.18}An Autotuning Framework for Scalable Execution of Tiled Code via Iterative Polyhedral Compilation}{10}{subsection.2.18}%
\contentsline {subsection}{\numberline {2.19}Employing polyhedral methods to optimize stencils on FPGAs with stencil-specific caches, data reuse, and wide data bursts}{10}{subsection.2.19}%
\contentsline {subsection}{\numberline {2.20}Modelling linear algebra kernels as polyhedral volume operations}{11}{subsection.2.20}%
\contentsline {subsection}{\numberline {2.21}Automated Partitioning of Data-Parallel Kernels using Polyhedral Compilation}{11}{subsection.2.21}%
\contentsline {subsection}{\numberline {2.22}Superloop Scheduling: Loop Optimization via Direct Statement Instance Reordering}{11}{subsection.2.22}%
\contentsline {subsection}{\numberline {2.23}Pipelined Multithreading Generation in a Polyhedral Compiler}{12}{subsection.2.23}%
\contentsline {subsection}{\numberline {2.24}Compiling affine loop nests for distributed-memory parallel architectures}{12}{subsection.2.24}%
\contentsline {subsection}{\numberline {2.25}Dynamic memory access monitoring based on tagged memory}{12}{subsection.2.25}%
\contentsline {subsection}{\numberline {2.26}Effective automatic computation placement and data allocation for parallelization of regular programs}{12}{subsection.2.26}%
